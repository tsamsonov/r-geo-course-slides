---
title: "Временные ряды"
subtitle: "Визуализация и анализ географических данных на языке R"
author: "Тимофей Самсонов"
institute: "МГУ имени Ломоносова, Географический факультет"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, "custom.css"]
    lib_dir: libs
    nature:
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r setup, echo = FALSE, purl = FALSE, cache = FALSE, include=FALSE}
library(datasets)
knitr::opts_knit$set(global.par = TRUE)
knitr::opts_chunk$set(warning=FALSE, collapse=TRUE, message = FALSE, dpi=300)
```

## Используемые пакеты:

.pull-left[
__tidyverse__
```{r}
# tidyverse
library(tidyverse)
library(readxl)
library(googlesheets4)
```

__Данные__
```{r}
library(tsibbledata)
library(nasapower)
```
]

.pull-right[
__Временные данные__
```{r}
# пакеты для временных данных
library(gganimate)
library(zoo)
library(trend)
library(tsibble)
library(feasts)
library(fable)
```
]


---

## Основные аспекты работы с временными рядами

1. Типы данных времени
2. Структуры данных для временных рядов
3. Преобразования времени и временных рядов
4. Декомпозиция временных рядов
5. Анализ трендов и автокорреляции
6. Построение моделей и прогнозирование
7. Визуализация и анимация


---

## Создание и преобразование дат и времени

Текущее время и дата:

```{r}
(date = Sys.Date())
(time = Sys.time())
```

Полученные объекты имеют типы `Date` и `POSIXct`:
```{r}
class(date)
class(time)
```

---

## Система счета времени

Время `POSIXct` хранится в целочисленном формате и отсчитывается начиная с начала эпохи UNIX — $1$ января $1970$ года по гринвичскому (_UTC_) времени:

```{r}
as.integer(date)
difftime(date, as.Date('1970-01-01'))

as.integer(time)
difftime(time, as.POSIXct('1970-01-01 00:00:00', tz = 'UTC'), units = 'secs')
```

---

## Работа с данными в lubridate

__Создание__ дат возможно на основе целочисленных и строковых значений:
```{r}
ymd(20150515)
dmy('15052015')
```

Для создания отметки времени необходимо сформировать строку, которая может быть интерпретирована должным образом. Часовой пояс указывается в `tz`:
```{r}
ymd_hms('2015-05-15 22:15:34') # по умолчанию Гринвичское время
ymd_hms('2015-05-15 22:15:34', tz = "Europe/Moscow")
```

---

## Работа с данными в lubridate

.pull-left[
__Извлечение__ компоненты даты/времени:
```{r}
year(time)
month(time)
week(time)
day(time)
hour(time)
second(time)
```

> Недели отсчитываются от начала года, а не месяца.

]

.pull-right[
__Замена__ компонент даты/времени:
```{r}
year(time) = 2015
month(time) = 01
time
```

__Округление__ даты/времени. Например, получить первый день в текущем году можно так:
```{r}
floor_date(Sys.Date(), 
           unit = 'year')
```
]
 
---

## Работа с данными в lubridate

__Периоды__  (_periods_) — это промежутки дат с точностью до _дня_. С помощью периода можно, например, к дате прибавить 1 год, 4 месяца, 3 недели и 2 дня:
```{r}
date
date + years(1) + months(4) + weeks(3) + days(2)
```

__Длительности__ (_durations_) — это промежутки времени с точностью до _секунды_. Работают они в целом аналогично периодам:
```{r}
dweeks(1)
time
time + dweeks(1)
time + weeks(1)
```

---

## Работа с данными в lubridate

__Интервалы__ — это отрезки между двумя датами. Интервал можно преобразовывать в периоды и длительности:
```{r}
int = lubridate::interval(Sys.time(), time)
int
as.period(int, 'days')
as.duration(int)
```

---

## Восстановление пропусков

В качестве источника данных будем использовать данные об уровне воды на гидропосте Паялка (р. Умба, Мурманская область) с 1932 по 2014 год. Отсутствие информации в файле данных закодировано числом `9999`:
```{r}
src = read_delim('../r-geo-course/data/in_Umba.txt', delim = ' ', 
      col_names = c('day', 'month', 'year', 'level'), na = '9999')
head(src)
```

---

## Восстановление пропусков

Сформируем даты на основе первых трёх столбцов и проверим, все ли из них корректны. Если компоненты даты некорректны, то функция `yms()` вернет `NA`:

.left-60[
```{r}
tab = src |>
    mutate(Date = ymd(paste(year, 
                            month, 
                            day)))
tab |> 
  filter(is.na(Date))
```
]

.right-40[
<br>
Проверка показала, что преобразование в дату оказалось невозможно только для одной строки. В этой строке оператором была введена несуществующая дата — 29 февраля 1941 года. 

Для дальнейшей работы необходимо избавиться от некорректных дат.
]

---

## Создание временного фрейма данных (tsibble)

__tsibble__ — это временной фрейм данных, у которого есть индекс в виде временного столбца:

```{r}
tsbl = tab |> 
  filter(!is.na(Date)) |> 
  distinct(Date, .keep_all = T) |> 
  as_tsibble(index = Date)

tsbl
```

---

## Восстановление пропусков

Для того чтобы выяснить, есть ли пропуски, можно использовать `scan_gaps()` (индивидуальные пропуски) или `count_gaps()` (периоды пропусков)
```{r}
scan_gaps(tsbl)
count_gaps(tsbl)
```

---

## Восстановление пропусков

Для устранения пропусков дат используем `fill_gaps()`:
```{r}
tsbl = fill_gaps(tsbl)
scan_gaps(tsbl)
```


---

## Заполнение пропусков данных

Создание таблицы пропусков:
```{r}
find_gaps = function(df, variable) {
  df |> 
    as_tibble() |>
    mutate(type = if_else(is.na(df[variable]), 'gap', 'data'),
           num = with(rle(type), rep(seq_along(lengths), lengths))) |> 
    group_by(num) |> 
    summarise(start_date = min(Date),
              end_date = max(Date),
              duration = end_date - start_date + 1,
              type = first(type))
}
timerep = find_gaps(tab, 'level')
```

---

## Заполнение пропусков

```{r, echo = FALSE}
DT::datatable(timerep, height = 500)
```

---

## Автокорреляция

Критическую длину пропуска, заполняемого интерполяцией, можно связать с пороговым значением __автокорреляции__ — коэффициента корреляции исходного ряда данных и его копии, полученной со сдвигом $\tau$.

.pull-left[
```{r acf}
acorr = tsbl |> ACF(level)
acorr
```

]

.pull-right[
```{r, fig.height=4}
autoplot(acorr)
```
]

---

## Анализ АКФ

За допустимую величину автокорреляции при восстановлении рядов данных принято брать некоторое значение. Например, гидрологи часто используют $0.7$. Найдем индекс первого элемента менее данной величины, используя функцию `detect_index()` из пакета __purrr__:

```{r}
max_dur = purrr::detect_index(acorr$acf, ~ .x < 0.7)
max_dur
```

Полученное значение говорит нам о том, что при заданном допуске допустимо интерполировать значения в пропусках данных короче, чем `r max_dur` дней.


---

## Интерполяция по времени

Для начала визуализируем участок в окрестности одного из пробелов

```{r, fig.height=2.5}
autoplot(tsbl, level, size = 1) +
  scale_x_date(limits = c(ymd(19320101), ymd(19360101)))
```

---

## Интерполяция по времени (линейная)

Для выполнения обычной линейной интерполяции между пропускаи воспользуемся функцией `na.approx()` из пакета __zoo__ и округлим полученные значения до одного знака после запятой (что соответствует точности исходных данных):

```{r}
(tsbl_int = tsbl |> 
  mutate(level_interp = 
           zoo::na.approx(level, maxgap = max_dur) |> round(1)))
```


---

## Интерполяция по времени (линейная)

Визуализируем результат:
```{r, fig.height=2.2}
autoplot(tsbl_int, level_interp, color = 'red', size = 1) +
  geom_line(aes(Date, level), tsbl, linewidth = 1) +
  scale_x_date(limits = c(ymd(19320101), ymd(19360101)))
```

---

## Интерполяция по времени (с авторегрессией)

Ту же задачу можно решить с применением модели [ARIMA](https://ru.wikipedia.org/wiki/ARIMA), которая подыскивает интерполятор с учетом авторегрессии и сглаживающего среднего. 

```{r}
tsbl_int2 = tsbl |> 
  model(mdl = ARIMA(level ~ 0 + pdq(0,1,0) + PDQ(0,0,0))) |> 
  interpolate(tsbl)
```

$$\triangle^d X_t=c+\sum_{i=1}^p a_i\triangle^d X_{t-i}+\sum_{j=1}^q b_j\varepsilon_{t-j}+\varepsilon_t$$

- $X_t$ — исходный нестационарный временной ряд
- $c, a_i, b_j$ — параметры модели
- $\triangle^d$ — оператор разности порядка $d$ (применение оператора `diff` $d$ раз)
- $\epsilon_t$ — ошибка (стационарный временной ряд)
- `pdq` — постоянная компонента, `PDQ` — сезонная компонента. 

---

## Интерполяция по времени (с авторегрессией)

Однако в простейшем случае здесь есть проблемы с немонотонными участками (начало 1935 года).

```{r, fig.height=2.2}
autoplot(tsbl_int2, level, color = 'magenta', size = 1) +
  geom_line(mapping = aes(Date, level), tsbl, linewidth = 1) +
  scale_x_date(limits = c(ymd(19320101), ymd(19360101)))
```
---

## Интерполяция с учетом предикторов

Используем данные по температуре и осадкам и посчитаем по ним скользящее среднее за 10 и 5 дней соответственно:

```{r}
meteo = read_delim('../r-geo-course/data/in_Umba_meteo.txt', delim = ' ', 
                 col_names = c('day', 'month', 'year', 'temp', 'prec'), na = '9999') |> 
  mutate(Date = ymd(paste(year, month, day)),
         tempsm = zoo::rollmean(temp, 10, fill = NA, align = 'center'),
         precsum = zoo::rollsum(prec, 5, fill = NA, align = 'center')) |> 
  select(Date, temp, tempsm, prec, precsum)

tsbl_all = left_join(tsbl_int, meteo, by = 'Date')
tsbl_all
```

---

## Интерполяция с учетом предикторов

Выполним интерполяцию методом ARIMA с внешними предикторами:

```{r}
tsbl_int_met = tsbl_all |> 
  model(mdl = ARIMA(level_interp ~ tempsm + precsum)) |> 
  interpolate(tsbl_all)
```

---

## Интерполяция с учетом предикторов

Визуализируем результат:

```{r, fig.height=2.2}
autoplot(tsbl_int_met, level_interp, color = 'green', size = 1) +
  geom_line(aes(Date, level_interp), tsbl_all, linewidth = 1) +
  scale_x_date(limits = c(ymd(19320101), ymd(19360101)))
```

---

## Пересчет на другую временную сетку

Загрузим в качестве примера данные по метеостанции __NETATMO__:
```{r}
tab = read_csv('../r-geo-course/data/70_ee_50_00_8e_1a.csv')
```
```{r echo = F}
DT::datatable(tab, height = 400, options = list(scrollX = TRUE))
```


---

## Пересчет на другую временную сетку

Определим расчетные интервалы, кратные 30 минутам:
```{r}
tab = tab |> select(id, temperature, time_temperature)

tmin = ceiling_date(min(tab$time_temperature), 
                    unit = '30 minutes')
tmax = floor_date(max(tab$time_temperature), 
                  unit = '30 minutes')
```

---

## Пересчет на другую временную сетку

Проинтерполуруем данные на единую регулярную временную сетку через $30$ минут, используя функцию [`approx()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/approxfun.html) из базового __R__:
```{r}
time_interp = tibble(
  datetime = seq(tmin, tmax, by = '30 min'),
  temp = round(approx(tab$time_temperature, 
                      tab$temperature, 
                      xout = datetime)$y, 1)
)
```

---

## Пересчет на другую временную сетку

```{r, echo=F}
DT::datatable(time_interp, height = 500)
```


---

## Обеспеченность данными

Надежность каждого интерполированного значения можно оценить, задав максимальную продолжительность интерполируемого интервала. Предположим, что она не должна превышать $60$ минут:

```{r}
idx = sapply(time_interp$datetime, \(x) match(TRUE, tab$time_temperature >= x))

time_interp = time_interp |> 
  mutate(before_time = datetime - tab$time_temperature[idx-1],
         after_time = tab$time_temperature[idx] - datetime,
         valid = after_time - before_time <= minutes(60))

cat('Valid are ', round(100 * sum(time_interp$valid) / nrow(time_interp), 1), 
    '% of interpolated values', sep = '')
```


---

## Обеспеченность данными

```{r, echo=F}
DT::datatable(time_interp, height = 500)
```

---

## Прогнозирование по времени

Рассмотрим задачу прогнозирования количества [потребляемой электроэнергии](https://otexts.com/fpp3/forecasting.html#example-forecasting-electricity-demand) в штате Виктория (Австралия) в зависимости от температуры воздуха.

.code-small[
```{r}
data(vic_elec, package = 'tsibbledata')

vic_elec_daily = vic_elec |> 
  filter(year(Time) == 2014) |> 
  index_by(Date = date(Time)) |> 
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) |> 
  mutate(Day_Type = case_when(
    Holiday ~ "Holiday",
    wday(Date) %in% 2:6 ~ "Weekday",
    TRUE ~ "Weekend"
  ))
```
]

---

## Прогнозирование по времени

Визуализируем исходные данные:

```{r, fig.height=2}
vic_elec_daily |> 
  pivot_longer(c(Demand, Temperature)) |> 
    ggplot(aes(x = Date, y = value)) +
    geom_line() +
    facet_grid(name ~ ., scales = "free_y") + ylab("")
```

---

## Прогнозирование по времени

Выполним построение модели и сформируем прогнозные данные по температуре:
```{r}
fit = vic_elec_daily |> 
  model(ARIMA(Demand ~ Temperature + I(Temperature^2) +
                (Day_Type == "Weekday")))

vic_elec_future = new_data(vic_elec_daily, 14) |> 
  mutate(
    Temperature = 26,
    Holiday = c(TRUE, rep(FALSE, 13)),
    Day_Type = case_when(
      Holiday ~ "Holiday",
      wday(Date) %in% 2:6 ~ "Weekday",
      TRUE ~ "Weekend"
    )
  )
```

---

## Прогнозирование по времени

Выполним прогнозирование:
```{r, fig.height=2}
forecast(fit, vic_elec_future) |> 
  autoplot(vic_elec_daily) +
  labs(title="Daily electricity demand: Victoria",
       y="GW") +
  scale_x_date(limits = c(ymd(20141001), ymd(20150115)))
```


---

## Аппроксимация по времени

В качестве примера возьмем данные межгодичных изменений характеристик стока реки Мезень на посту Малонисогорская:

```{r}
(tab = read_csv('../r-geo-course/data/Mezen.csv'))
```

---

## Аппроксимация по времени

Построим график межгодичной изменчивости объема грунтового стока (переменная `Wgr` в $км^3$). Для того чтобы нанести линию глобального тренда, добавим грамматику `geom_smooth(method = 'lm')`:

.pull-left[
.code-small[
```{r wgr, eval = F}
ggplot(
  tab, 
  mapping = aes(Year1, Wgr)
) +
  geom_line() +
  geom_area(alpha = 0.5) +
  geom_smooth(method = 'lm') +
  labs(
    title = 'Объем грунтового стока',
    x = 'Год',
    y = expression(км^3)
  )
```
]
]

.pull-right[
```{r wgr-out, ref.label='wgr', echo=F, fig.height=3, fig.width=4}
```
]

---

## Аппроксимация по времени

Добавим линию локальной регрессии `geom_smooth(method = 'loess')`:

.pull-left[
.code-small[
```{r wgr2, eval = F}
ggplot(
  tab, 
  mapping = aes(Year1, Wgr)
) +
  geom_line() +
  geom_area(alpha = 0.5) +
  geom_smooth(method = 'lm') +
  geom_smooth(
    method = 'loess',
    color = 'orangered', 
    span = 0.2
  ) +
  labs(
    title = 'Объем грунтового стока',
    x = 'Год',
    y = expression(км^3)
  )
```
]
]

.pull-right[
```{r wgr2-out, ref.label='wgr2', echo=F, fig.height=3.5, fig.width=4}
```
]

---

## Локальная регрессия

Нанесем несколько кривых локальной регрессии, используя разный охват данных:

.pull-left[
.code-small[
```{r loess, eval=F}
ggplot(
  tab, 
  mapping = aes(Year1, Wgr)
) +
  geom_line() +
  geom_area(alpha = 0.5) +
  geom_smooth(color = 'yellow', 
              span = 0.1) +
  geom_smooth(color = 'orangered', 
              span = 0.2) +
  geom_smooth(color = 'darkred', 
              span = 0.4) +
  labs(
    title = 'Объем грунтового стока',
    x = 'Год',
    y = expression(км^3)
  )
```
]
]

.pull-right[
```{r loess-out, ref.label='loess', echo=F, fig.height=3.5, fig.width=4}
```
]


---

## Статистики

При анализе временных рядов часто используются:

- Тест Манна-Кендалла на значимость линейного тренда
- Тест Петтитт на точку перелома
- Оценка величины тренда по методу Тейла-Сена

Эти тесты доступны в пакете __trend__:

.code-small[
```{r}
(mk = mk.test(tab$Wgr))
```
]


---

## Статистики

.code-small[
```{r}
(pt = pettitt.test(tab$Wgr))
(ts = sens.slope(tab$Wgr))
```
]


---

## Статистики

.pull-left[
.code-small[
```{r pt, eval=F}
ggplot(tab, aes(Year1, Wgr)) +
  geom_line() +
  geom_area(alpha = 0.5) +
  geom_smooth(method = 'lm') +
  geom_vline(
    xintercept = tab$Year1[pt$estimate], 
    color = "red", size = 0.5
  ) +
  annotate(
    "text", 
    label = tab$Year1[pt$estimate], 
    x = tab$Year1[pt$estimate] + 4, 
    y = max(tab$Wgr), 
    size = 4, colour = "red"
  ) +
  labs(
    title = 'Объем грунтового стока',
    x = 'Год',
    y = expression(км^3)
  )
```
]
]

.pull-right[
Для наглядности нанесем полученную точку перелома на график:
```{r pt-out, ref.label = 'pt', echo=F, fig.height=3.5, fig.width=4}
```
]

---

## Анимация

Возможности анимаций в __gganimate__ реализуются посредством добавления новых грамматик к построенному графику __ggplot2__. К числу этих грамматик относятся:

- `transition_*()` — распределение данных по времени;
- `view_*()` — поведение осей координат во времени;
- `shadow_*()` — отображение данных, не относящихся к текущему временному срезу;
- `enter_*()/exit_*()` — характер появления/исчезновения данных в процессе анимации;
- `ease_aes()` — порядок смягчения (интерполяции) графических переменных в моменты перехода.

---

## Анимация

В качестве первого примера используем данные реанализа NASA POWER суточного осреднения, выгрузив информацию по точкам в трех городах (Мурманск, Москва, Краснодар) за 2018 год:
```{r, eval = FALSE}
cities = list(Мурманск = c(33, 69), 
              Москва = c(38, 56), Краснодар = c(39, 45))

tab = purrr::imap(cities, function(coords, city){
  get_power(
    community = "AG",
    lonlat = coords,
    pars = c("RH2M", "T2M", "PRECTOT"),
    dates = c("2018-01-01", "2018-12-31"),
    temporal_average = "DAILY"
  ) |> mutate(CITY = city,
               MONTH = month(YYYYMMDD))
}) |> bind_rows()
```

---

## Переход по времени

```{r, eval = FALSE}
ggplot(tab, aes(CITY, T2M)) +
  geom_boxplot() +
  labs(title = "Температура воздуха",
    subtitle = 'Месяц: {round(frame_time)}') + #<<
  xlab('Город') + ylab('Т, °С') +
  transition_time(MONTH) #<<
```

```{r, echo = FALSE, out.width='45%'}
# anim = ggplot(tab, aes(CITY, T2M)) +
#   geom_boxplot() +
#   labs(title = "Температура воздуха в 2018 году по данным NASA POWER",
#        subtitle = 'Месяц: {round(frame_time)}') +
#   xlab('Город') +
#   ylab('Т, °С') +
#   transition_time(MONTH)
# anim_save('images/boxplot_anim.gif',
#           animation = animate(anim))
knitr::include_graphics('img/boxplot_anim.gif')
```

---

## Переход по времени

.pull-left[
```{r, eval = FALSE}
ggplot(tab, aes(T2M, fill = CITY)) +
  geom_density(alpha = 0.5) + #<<
  labs(
    title = "Температура воздуха",
    subtitle = 'Месяц: {round(frame_time)}',
    fill = 'Город'
  ) +
  xlab('Т, °С') +
  ylab('Плотность распределения') +
  transition_time(MONTH)
```
]

.pull-right[
Плотность распределения:
```{r, echo = FALSE}
# anim = ggplot(tab, aes(T2M, fill = CITY)) +
#   geom_density(alpha = 0.5) +
#   labs(title = "Температура воздуха в 2018 году по данным NASA POWER",
#        subtitle = 'Месяц: {round(frame_time)}',
#        fill = 'Город') +
#   xlab('Т, °С') +
#   ylab('Плотность распределения') +
#   transition_time(MONTH)
# anim_save('images/density_anim.gif',
#           animation = animate(anim))
knitr::include_graphics('img/density_anim.gif')
```
]

---

## Переход по времени

Данные Gapminder по соотношению продолжительности жизни и ВВП:
.code-small[
```{r, eval=FALSE}
countries = read_excel('../r-geo-course/data/gapminder.xlsx', 2) |>
  select(Country = name, Region = eight_regions) |>
  mutate(Country = factor(Country, levels = Country[order(.$Region)]))
# ВВП на душу населения
gdpdf_tidy = read_sheet('1cxtzRRN6ldjSGoDzFHkB8vqPavq1iOTMElGewQnmHgg') |> 
  pivot_longer(cols = `1764`:`2018`, names_to = 'year', values_to = 'gdp') |> 
  rename(Country = 1)
# численность населения
popdf_tidy = read_sheet('1IbDM8z5XicMIXgr93FPwjgwoTTKMuyLfzU6cQrGZzH8') |> 
  pivot_longer(cols = `1800`:`2015`, names_to = 'year', values_to = 'pop') |> 
  rename(Country = 1)
```
]

---

## Переход по времени

Данные Gapminder по соотношению продолжительности жизни и ВВП:

.code-small[
```{r, eval=FALSE}
# продолжительность жизни
lifedf_tidy = read_sheet('1H3nzTwbn8z4lJ5gJ_WfDgCeGEXK3PVGcNjQ_U5og8eo') |>
  pivot_longer(cols = `1800`:`2016`, names_to = 'year', values_to = 'lifexp') |> 
  rename(Country = 1)

tab = gdpdf_tidy |> 
  inner_join(lifedf_tidy) |> 
  inner_join(popdf_tidy) |> 
  inner_join(countries) |> 
  mutate(year = as.integer(year)) |> 
  drop_na()
```
]

---

## Переход по времени

.pull-left[
.code-small[
```{r, eval = FALSE}
options(scipen = 999)
ggplot(
  tab, aes(
    gdp, lifexp, 
    size = pop, 
    color = Region
  )
) +
  geom_point(alpha = 0.5) +
  scale_x_log10() +
  labs(title = 
       'Year: {round(frame_time)}') +
  theme_bw() +
  transition_time(year)
```
]
]

.pull-right[
```{r, echo=FALSE}
options(scipen = 999)
# anim = ggplot(tab, aes(gdp, lifexp, size = pop, color = Region)) +
#   geom_point(alpha = 0.5) +
#   scale_x_log10() +
#   labs(title = 'Year: {round(frame_time)}') +
#   theme_bw() +
#   transition_time(year)
# anim_save('images/scatter_anim.gif',
#           animation = animate(anim))
knitr::include_graphics('img/scatter_anim.gif')
```
]


---

# Переход по состояниям

- В ряде случаев вместо перехода по времени целесообразно использовать __переход по состояниям__. В частности, такой подход оказывается удобен, когда сопоставляются данные за аналогичные временные срезы разных периодов. 


- Подобную стратегию можно использовать для визуализации изменений внутригодичного распределения величины между годами. 


- Чтобы обеспечить сопоставимость аналогичных дат за разные года, необходимо сохранить у них только месяц и день. 


- Поскольку такого формата даты не существует, в качестве "трюка" можно просто заменить года всех дат на $2000$ и записать результат в новое поле. 

---

# Переход по состояниям

Необходимые преобразования реализуются следующим образом:
```{r}
flt_tab = tsbl_int |> 
  filter(!is.na(year)) |> 
  group_by(year) |>
  filter(!all(is.na(level_interp))) |> 
  ungroup() |> 
  mutate(yDate = Date)

# фиктивное поле, в котором аналогичные даты за разные года совпадают
year(flt_tab$yDate) <- 2000 
```

---

# Переход по состояниям

```{r, eval=FALSE}
anim = ggplot(flt_tab, mapping = aes(x = yDate, y = level_interp)) +
    geom_ribbon(aes(ymin = 0, ymax = level_interp), alpha = 0.5) +
    geom_line() +
    scale_x_date(date_breaks = "1 month", date_labels = "%b") +
    labs(title = "Расход воды на гидропосту Паялка",
         subtitle = 'Год: {closest_state}') +
    xlab('Дата') +
    ylab('куб.м/с') +
    theme(text = element_text(size = 18, family = 'Open Sans')) +
    transition_states(year, state_length = 0) + #<<
    view_follow(fixed_y = TRUE) #<<

animate(anim, 
        fps = 20,                                    # число кадров в секунду
        nframes = 10 * length(unique(flt_tab$year)), # общее число кадров
        width = 800, 
        height = 600)
```

---

# Переход по состояниям

```{r, echo=FALSE, out.width='65%'}
knitr::include_graphics('img/hydrograph_anim.gif')
```

> Текущий срез при выполнении анимации по состояниям доступен в переменной окружения `closest_state`.


---

<!-- --- -->

<!-- ## Локальная регрессия -->

<!-- .red[Метод __локальной регрессии__ изначально был разработан для построения кривых регрессии в случае когда зависимость между переменными ведет себя сложным образом и не может быть описана в терминах традиционной линейной и нелинейной регрессии — глобальных методов.] -->

<!-- .pull-left[ -->
<!-- <br> -->
<!-- .small[.blue[Область значений независимой переменной $X$ можно покрыть конечным числом отрезков, для каждого из которых далее находят регрессию традиционным методом — как правило, линейную или квадратичную. Данный метод получил название _LOWESS (Locally weighted scatterplot smoothing)_. В дальнейшем эта аббревиатура была редуцирована до _LOESS_.]] -->
<!-- ] -->

<!-- .pull-right[ -->
<!-- ```{r wgr2-out, ref.label='wgr2', echo=F, fig.height=5.5} -->
<!-- ``` -->
<!-- ] -->

<!-- --- -->

<!-- ## Локальная регрессия -->

<!-- В классической постановке метод __LOESS__ реализуется следующим образом:  -->

<!-- - Пусть дано $n$ точек исходных данных с координатами $x$ (независимая переменная) и $y$ (зависимая).  -->

<!-- - Задается число $0 < \alpha \leq 1$, которое обозначает долю от общего количества точек $n,$ выбираемую в окрестности каждой точки для построения регрессии.  -->

<!-- - В абсолютном исчислении количество ближайших точек будет равно $r = [\alpha n]$, где $[\cdot]$ — округление до ближайшего целого. -->

<!-- Тогда вес, который будет иметь каждая $k$-я точка исходных данных в уравнении регрессии для $i$-й точки исходных данных будет определяться по формуле: -->

<!-- $$w_k (x_i) = W\big((x_k - x_i)h_i^{-1}\big),$$ -->
<!-- где $h_i$ — расстояние до $r$-го по близости соседа точки $x_i$, а $W$ — весовая функция: -->

<!-- --- -->

<!-- ## Локальная регрессия -->

<!-- $$w_k (x_i) = W\big((x_k - x_i)h_i^{-1}\big)$$ -->

<!-- 1. $W(x) > 0$ если $|x| < 1$; -->
<!-- 2. $W(-x) = W(x)$; -->
<!-- 3. $W(x)$ невозрастающая функция для $x \geq 0$; -->
<!-- 4. $W(x) = 0$ если $|x| \geq 1$. -->

<!-- Одним из стандартных вариантов весовой функции является _"трикубическая"_ функция, определяемая как: -->

<!-- $$ -->
<!-- W(x) = \begin{cases} -->
<!-- (1 - |x|^3)^3, & \text{если } |x| < 1, \\ -->
<!--  0, & \text{если } |x| \geq 1. -->
<!-- \end{cases} -->
<!-- $$ -->

<!-- Более близкие к $x_i$ точки оказывают большее влияние на коэффициенты регрессии. Помимо этого за пределами расстояния $h_i$ веса всех точек исходных данных будут обнуляться.  -->

<!-- --- -->

<!-- ## Локальная регрессия -->

<!-- Сглаженная оценка $\hat{y}_i$ в точке $x_i$ получается в виде полинома степени $d$: -->

<!-- $$\hat{y}_i = \sum_{j=0}^d \hat{\beta}_j (x_i) x_i^j,$$ -->
<!-- где коэффициенты $\hat{\beta}_j$ находятся методом наименьших квадратов путем минимизации ошибки: -->

<!-- $$\sum_{k=1}^n w_k (x_i) (y_k - \beta_0 - \beta_1 x_k - ... - \beta_d x_k^d)^2$$ -->
<!-- Процедура поиска коэффициентов регрессии повторяется для каждой из $n$ точек.  -->

<!-- --- -->

<!-- ## Локальная регрессия -->

<!-- В методе __LOESS__ используются степени регрессии $d = 0, 1, 2$. Кубические и более высокие степени полиномов на практике не применяются.  -->

<!-- > При степени равной 0 метод носит название _сглаживающего среднего_.  -->

<!-- Для построения линии локальной регрессии используйте функцию `geom_smooth()` без параметра `method` или с явным указанием параметра `method = 'loess'`: -->

<!-- Поведением локальной регрессии можно управлять, задавая параметры  -->

<!-- - `n` (количество ближайших точек $r$),  -->
<!-- - `span` (доля ближайших точек $\alpha$) -->
<!-- - `formula` (формула аппроксимируемой зависимости).  -->

<!-- По умолчанию используется регрессия первой степени (`formula = y ~ x`), значения `n = 80` и `span = 0.75`.  -->
